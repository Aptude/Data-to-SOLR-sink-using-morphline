# Specify server locations in a SOLR_LOCATOR variable; used later in 
# variable substitutions:
SOLR_LOCATOR : {
  # Name of solr collection
  collection : testcollection
  
  # ZooKeeper ensemble
  zkHost : "localhost.localdomain:2181/solr"  
}

# Specify an array of one or more morphlines, each of which defines an ETL
# transformation chain. A morphline consists of one or more potentially
# nested commands. A morphline is a way to consume records such as Flume events,
# HDFS files or blocks, turn them into a stream of records, and pipe the stream
# of records through a set of easily configurable transformations on the way to
# a target application such as Solr.
morphlines : [
  {
    id : morphline1
    importCommands : ["org.kitesdk.**"]

    commands : [
      {
        readLine {
          charset : UTF-8
        }
      }

        
     {
        grok {
          # a grok-dictionary is a config file that contains prefabricated regular expressions
          # that can be referred to by name.
          # grok patterns specify such a regex name, plus an optional output field name.
          # The syntax is %{REGEX_NAME:OUTPUT_FIELD_NAME}
          # The input line is expected in the "message" input field.
          dictionaryFiles : ["/opt/cloudera/parcels/CDH/share/doc/search-1.0.0+cdh5.0.2+0/examples/solr-nrt/grok-dictionaries"]
          expressions : {
            file:"""/.*?/.*?/.*?/.*?/%{DATA:country}_%{DATA:timestamp}_%{DATA:filename}""" 
	    message : """%{DATA:event_message}"""
          }
        }
      }

      {
        convertTimestamp {
          field : timestamp
          inputFormats : ["yyMMddHHmm"]
          inputTimezone : America/Chicago
          outputFormat : "yyyy-MM-dd HH:mm"
          outputTimezone : America/Chicago
        }
      }
	
      {
        java {
          imports : """
            import java.util.*;
          """
          code: """
   		record.replaceValues("country",((String)record.getFirstValue("country")).toUpperCase());	
		String fileName =(String)record.getFirstValue("filename"); 
		record.replaceValues("filename",fileName.substring(0, fileName.indexOf('.')).toUpperCase());	
		String eventMessage = (String)record.getFirstValue("event_message");
		eventMessage = eventMessage.replaceAll("\\|","<br>");
		eventMessage = eventMessage.replaceAll("\\[tab\\]","&nbsp\\;&nbsp\\;&nbsp\\;&nbsp\\;");
		                
		record.replaceValues("event_message",eventMessage);
		
            return child.process(record);
          """
        }
      }
    



      # Consume the output record of the previous command and pipe another
      # record downstream.
      #
      # This command deletes record fields that are unknown to Solr 
      # schema.xml.
      #
      # Recall that Solr throws an exception on any attempt to load a document 
      # that contains a field that is not specified in schema.xml.
      {
        sanitizeUnknownSolrFields {
          # Location from which to fetch Solr schema
          solrLocator : ${SOLR_LOCATOR}
        }
      }  
            
      # log the record at DEBUG level to SLF4J
      { logDebug { format : "output record: {}", args : ["@{}"] } }    
      
      # load the record into a Solr server or MapReduce Reducer
      { 
        loadSolr {
          solrLocator : ${SOLR_LOCATOR}
        }
      }

    ]
  }
]
